{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   0 15000001 2019-09-10\n",
       " 0  1 15000002 2019-09-05\n",
       " 1  2 15000003 2019-09-03\n",
       " 2  3 15000004 2019-09-01\n",
       " 3  4 15000005 2019-09-16\n",
       " 4  5 15000006 2019-08-23,\n",
       " (99, 1))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, train_path, num_rows):\n",
    "        if num_rows == -1:\n",
    "            self.train_data = pd.read_csv(train_path, sep = '\\t')\n",
    "            self.num_rows = self.train_data.shape[0]\n",
    "        else:\n",
    "            self.train_data = pd.read_csv(train_path, sep = '\\t', nrows = num_rows)\n",
    "            self.num_rows = num_rows\n",
    "\n",
    "    def show_train(self, num_rows):\n",
    "        return self.train_data.head(num_rows)\n",
    "\n",
    "    # handles dataset's missing values\n",
    "    def filter_by_cond(self, dataset, conds):\n",
    "        # conds is list of tuples, each tuple has column name and corresponding condition to check for when dropping rows from dataset\n",
    "        for col, condition in conds:\n",
    "            if condition == 'non negative':\n",
    "                dataset = dataset[dataset[col] >= 0]\n",
    "            elif condition == 'not missing':\n",
    "                dataset = dataset.dropna(subset = [col])\n",
    "            elif condition == 'not NONE':\n",
    "                dataset = dataset[dataset[col] != 'NONE']\n",
    "        return dataset\n",
    "\n",
    "    # returns dataset after dealing with missing values \n",
    "    def clean_data(self, dataset):\n",
    "        conds = [('carrier_min_estimate', 'non negative'), \n",
    "        ('carrier_max_estimate', 'non negative'),\n",
    "        ('declared_handling_days', 'not missing'),\n",
    "        ('package_size', 'not NONE')]\n",
    "        dataset = self.filter_by_cond(dataset, conds)\n",
    "        return dataset\n",
    "\n",
    "    # takes in a table and list of column names, label encodes the values in each column and returns the modified table \n",
    "    def label(self, table, col_names):\n",
    "        labeler = LabelEncoder()\n",
    "        for col in col_names:\n",
    "            table[col] = labeler.fit_transform(table[col])\n",
    "        return table\n",
    "\n",
    "    # takes in a table and list of column names, converts the values in each column to datetime and then to ordinal integer, returns modified table\n",
    "    def convert_to_ordinal(self, table, col_names):\n",
    "        for col in col_names:\n",
    "            table[col] = pd.to_datetime(table[col], utc = True)\n",
    "            table[col] = table[col].apply(datetime.toordinal)\n",
    "        return table\n",
    "\n",
    "    # returns a list of the columns with categorical values in a table\n",
    "    def list_cat_cols(self, table):\n",
    "        cat_selector = selector(dtype_include = object)\n",
    "        cat_cols = cat_selector(table)\n",
    "        return cat_cols\n",
    "\n",
    "    # returns a list of the columns with numerical values in a table\n",
    "    def list_num_cols(self, table):\n",
    "        num_selector = selector(dtype_exclude = object)\n",
    "        num_cols = num_selector(table)\n",
    "        return num_cols\n",
    "\n",
    "    # label encodes categorical columns, returns modified table \n",
    "    def transform_cols(self, table):\n",
    "        cat_cols, num_cols = self.list_cat_cols(table), self.list_num_cols(table)\n",
    "        table = self.label(table, cat_cols)\n",
    "        return table\n",
    "\n",
    "    # prepares x columns for model\n",
    "    def x_cols(self):\n",
    "        cleaned_set = self.clean_data(self.train_data)\n",
    "        x_data = cleaned_set.drop('delivery_date', axis = 1)\n",
    "        x_data = self.convert_to_ordinal(x_data, ['acceptance_scan_timestamp','payment_datetime'])\n",
    "        x_data = self.transform_cols(x_data)\n",
    "        return x_data\n",
    "    \n",
    "    # prepares y column for model \n",
    "    def y_cols(self):\n",
    "        cleaned_set = self.clean_data(self.train_data)\n",
    "        y_data = pd.to_datetime(cleaned_set['delivery_date'], utc = True)\n",
    "        y_data = y_data.apply(datetime.toordinal)\n",
    "        return y_data\n",
    "\n",
    "    def create_model(self, test_proportion):\n",
    "        model = xgb.XGBRegressor(colsample_bytree = 0.3, subsample = 0.5, max_depth = 3, gamma = 0.5, eta = 0.2)\n",
    "        x = self.x_cols()\n",
    "        y = self.y_cols()\n",
    "        model.fit(x, y)\n",
    "        return model \n",
    "\n",
    "    # fits the model and returns accuracy of predictions on the training data and test data\n",
    "    def test(self, test_proportion):\n",
    "        model = xgb.XGBRegressor(colsample_bytree = 0.3, subsample = 0.5, max_depth = 3, gamma = 0.5, eta = 0.2)\n",
    "        x = self.x_cols()\n",
    "        y = self.y_cols()\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = test_proportion)\n",
    "        model.fit(xtrain, ytrain)\n",
    "        kfold = KFold(n_splits = 10)\n",
    "        result = cross_val_score(model, xtest, ytest, cv = kfold)\n",
    "        return result, \"{a} out of {b} rows dropped\".format(a = self.num_rows - y.shape[0], b = self.num_rows)\n",

