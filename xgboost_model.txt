import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.compose import make_column_selector as selector
from sklearn.preprocessing import LabelEncoder
from datetime import datetime

class Model:

    def __init__(self, train_path, num_rows):
        if num_rows == -1:
            self.train_data = pd.read_csv(train_path, sep = '\t')
            self.num_rows = self.train_data.shape[0]
        else:
            self.train_data = pd.read_csv(train_path, sep = '\t', nrows = num_rows)
            self.num_rows = num_rows

    def show_train(self, num_rows):
        return self.train_data.head(num_rows)

    # handles dataset's missing values
    def filter_by_cond(self, dataset, conds):
        # conds is list of tuples, each tuple has column name and corresponding condition to check for when dropping rows from dataset
        for col, condition in conds:
            if condition == 'non negative':
                dataset = dataset[dataset[col] >= 0]
            elif condition == 'not missing':
                dataset = dataset.dropna(subset = [col])
            elif condition == 'not NONE':
                dataset = dataset[dataset[col] != 'NONE']
        return dataset

    # returns dataset after dealing with missing values 
    def clean_data(self, dataset):
        conds = [('carrier_min_estimate', 'non negative'), 
        ('carrier_max_estimate', 'non negative'),
        ('declared_handling_days', 'not missing'),
        ('package_size', 'not NONE')]
        dataset = self.filter_by_cond(dataset, conds)
        return dataset

    # takes in a table and list of column names, label encodes the values in each column and returns the modified table 
    def label(self, table, col_names):
        labeler = LabelEncoder()
        for col in col_names:
            table[col] = labeler.fit_transform(table[col])
        return table

    # takes in a table and list of column names, converts the values in each column to datetime and then to ordinal integer, returns modified table
    def convert_to_ordinal(self, table, col_names):
        for col in col_names:
            table[col] = pd.to_datetime(table[col], utc = True)
            table[col] = table[col].apply(datetime.toordinal)
        return table

    # returns a list of the columns with categorical values in a table
    def list_cat_cols(self, table):
        cat_selector = selector(dtype_include = object)
        cat_cols = cat_selector(table)
        return cat_cols

    # returns a list of the columns with numerical values in a table
    def list_num_cols(self, table):
        num_selector = selector(dtype_exclude = object)
        num_cols = num_selector(table)
        return num_cols

    # label encodes categorical columns, returns modified table 
    def transform_cols(self, table):
        cat_cols, num_cols = self.list_cat_cols(table), self.list_num_cols(table)
        table = self.label(table, cat_cols)
        return table

    # prepares x columns for model
    def x_cols(self):
        cleaned_set = self.clean_data(self.train_data)
        x_data = cleaned_set.drop('delivery_date', axis = 1)
        x_data = self.convert_to_ordinal(x_data, ['acceptance_scan_timestamp','payment_datetime'])
        x_data = self.transform_cols(x_data)
        return x_data
    
    # prepares y column for model 
    def y_cols(self):
        cleaned_set = self.clean_data(self.train_data)
        y_data = pd.to_datetime(cleaned_set['delivery_date'], utc = True)
        y_data = y_data.apply(datetime.toordinal)
        return y_data

    def create_model(self, test_proportion):
        model = xgb.XGBRegressor(colsample_bytree = 0.3, subsample = 0.5, max_depth = 3, gamma = 0.5, eta = 0.2)
        x = self.x_cols()
        y = self.y_cols()
        model.fit(x, y)
        return model 

    # fits the model and returns accuracy of predictions on the training data and test data
    def test(self, test_proportion):
        model = xgb.XGBRegressor(colsample_bytree = 0.3, subsample = 0.5, max_depth = 3, gamma = 0.5, eta = 0.2)
        x = self.x_cols()
        y = self.y_cols()
        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = test_proportion)
        model.fit(xtrain, ytrain)
        kfold = KFold(n_splits = 10)
        result = cross_val_score(model, xtest, ytest, cv = kfold)
        return result, "{a} out of {b} rows dropped".format(a = self.num_rows - y.shape[0], b = self.num_rows)


train_path = "C:\\Users\\vukpe\\Downloads\\ebay_dataset\\eBay_ML_Challenge_Dataset_2021\\eBay_ML_Challenge_Dataset_2021_train.tsv.gz"
quiz_path = "C:\\Users\\vukpe\\Downloads\\ebay_dataset\\eBay_ML_Challenge_Dataset_2021\\eBay_ML_Challenge_Dataset_2021_quiz.tsv.gz"
#test_model = Model(train_path, quiz_path, 50000)
#test_model.test(0.2)

model = Model(train_path, 100)
trained_model = model.create_model(0.2)

quiz_data = pd.read_csv("C:\\Users\\vukpe\\Downloads\\ebay_dataset\\eBay_ML_Challenge_Dataset_2021\\eBay_ML_Challenge_Dataset_2021_quiz.tsv.gz", 
sep = '\t')
quiz_model = Model(quiz_path, 100)

quiz_model.train_data.drop('delivery_date', axis = 1, inplace = True)
quiz_model.train_data = quiz_model.convert_to_ordinal(quiz_model.train_data, ['acceptance_scan_timestamp', 'payment_datetime'])
quiz_model.train_data = quiz_model.transform_cols(quiz_model.train_data)
x_data = quiz_model.train_data

predictions = pd.DataFrame()
predictions[0] = quiz_model.train_data['record_number']
predictions[1] = trained_model.predict(x_data)

predictions[1] = predictions[1].apply(int)
predictions[1] = predictions[1].apply(datetime.fromordinal)
predictions.to_csv('predictions.tsv', sep = " ", header = False)